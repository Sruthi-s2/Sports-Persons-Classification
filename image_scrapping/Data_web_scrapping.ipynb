{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f388ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 168\u001b[0m\n\u001b[0;32m    165\u001b[0m query \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mSerena Williams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m query:\n\u001b[1;32m--> 168\u001b[0m     search_and_download(q,\u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mcode\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mPROJECTS\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mSportsPersonClassifier\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmodel\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mchromedriver.exe\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[3], line 148\u001b[0m, in \u001b[0;36msearch_and_download\u001b[1;34m(search_term, driver_path, target_path, number_images)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(target_folder):\n\u001b[0;32m    146\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(target_folder)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mwith\u001b[39;00m webdriver\u001b[39m.\u001b[39;49mChrome(executable_path\u001b[39m=\u001b[39;49mdriver_path) \u001b[39mas\u001b[39;00m wd:\n\u001b[0;32m    149\u001b[0m     res \u001b[39m=\u001b[39m fetch_image_urls(search_term, number_images, wd\u001b[39m=\u001b[39mwd, sleep_between_interactions\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,driver_path\u001b[39m=\u001b[39m driver_path,target_path\u001b[39m=\u001b[39m target_path,search_term\u001b[39m=\u001b[39msearch_term)\n\u001b[0;32m    150\u001b[0m \u001b[39mtry\u001b[39;00m:    \n",
      "\u001b[1;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Code credit:\n",
    "https://towardsdatascience.com/image-scraping-with-python-a96feda8af2d\n",
    "Also thanks for Debjyoti Paul (my friend and data scientist at Amazon) for help with this\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import requests \n",
    "import io\n",
    "import hashlib\n",
    "import os\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def fetch_image_urls_util(url,driver_path):\n",
    "    images = []\n",
    "    # Open main window with URL A\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "\n",
    "        # Switch to the new window and open URL B\n",
    "        try:\n",
    "            wd.get(url)\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img[class ='irc_mi']\")\n",
    "\n",
    "        for img in thumbnail_results:\n",
    "            if img.get_attribute('src') and 'http' in img.get_attribute('src'):\n",
    "                images.append(img.get_attribute('src'))\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def fetch_image_urls(query:str, max_links_to_fetch:int, wd, sleep_between_interactions:int=1,driver_path= None, target_path = None, search_term = None):\n",
    "    \n",
    "    target_folder = os.path.join(target_path,'_'.join(search_term.lower().split(' ')))\n",
    "    def scroll_to_end(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(sleep_between_interactions)    \n",
    "    \n",
    "    # build the google query\n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
    "\n",
    "    # load the page\n",
    "    wd.get(search_url.format(q=query))\n",
    "\n",
    "    image_urls = set()\n",
    "    image_count = 0\n",
    "    image_count2 = 0\n",
    "    results_start = 0\n",
    "    i = 0\n",
    "    d = {}\n",
    "    while image_count < max_links_to_fetch:\n",
    "        scroll_to_end(wd)\n",
    "\n",
    "        # get all image thumbnail results\n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
    "        number_results = len(thumbnail_results)\n",
    "        \n",
    "        print(f\"Found: {number_results} search results. Extracting links from {results_start}:{number_results}\")\n",
    "        \n",
    "        for img in thumbnail_results[50:number_results]:\n",
    "            # try to click every thumbnail such that we can get the real image behind it\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(sleep_between_interactions)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "            links = wd.find_elements_by_css_selector(\"a[jsname='sTFXNd']\")\n",
    "\n",
    "            for link in links:\n",
    "                if link.get_attribute('href') and 'http' in link.get_attribute('href'):\n",
    "                    if link.get_attribute('href') not in d:\n",
    "                        d[link.get_attribute('href')] = True\n",
    "                        getactualurl = fetch_image_urls_util(link.get_attribute('href'),driver_path)\n",
    "                    for imageurl in getactualurl:\n",
    "                        if imageurl is not None:\n",
    "                            #print(imageurl)\n",
    "                            image_urls.add(imageurl)\n",
    "            \n",
    "            image_count2 = len(image_urls)\n",
    "            print(image_count2)\n",
    "            if image_count2 >= max_links_to_fetch/10:\n",
    "                print(f\"Found: {len(image_urls)} image links, saving!\")\n",
    "                try:    \n",
    "                    for elem in image_urls:\n",
    "                        persist_image(target_folder,elem)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                image_urls = set()\n",
    "                d = {}\n",
    "\n",
    "            image_count += image_count2\n",
    "                \n",
    "        #image_count = len(image_urls)\n",
    "\n",
    "        if len(image_urls) >= max_links_to_fetch:\n",
    "            print(f\"Found: {len(image_urls)} image links, done!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Found:\", len(image_urls), \"image links, looking for more ...\")\n",
    "            time.sleep(30)\n",
    "            return\n",
    "            load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\n",
    "            if load_more_button:\n",
    "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
    "\n",
    "        # move the result startpoint further down\n",
    "        results_start = image_count\n",
    "\n",
    "    print(len(image_urls))\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "\n",
    "def persist_image(folder_path:str,url:str):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not download {url} - {e}\")\n",
    "\n",
    "    try:\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "        file_path = os.path.join(folder_path,hashlib.sha1(image_content).hexdigest()[:10] + '.jpg')\n",
    "        with open(file_path, 'wb') as f:\n",
    "            image.save(f, \"JPEG\", quality=85)\n",
    "        print(f\"SUCCESS - saved {url} - as {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not save {url} - {e}\")\n",
    "        \n",
    "  \n",
    "    \n",
    "def search_and_download(search_term:str,driver_path:str,target_path='./datasets',number_images=50):\n",
    "    target_folder = os.path.join(target_path,'_'.join(search_term.lower().split(' ')))\n",
    "\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "        res = fetch_image_urls(search_term, number_images, wd=wd, sleep_between_interactions=0.5,driver_path= driver_path,target_path= target_path,search_term=search_term)\n",
    "    try:    \n",
    "        for elem in res:\n",
    "            persist_image(target_folder,elem)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "import time\n",
    "import requests \n",
    "import io\n",
    "from PIL import Image, ImageDraw\n",
    "import hashlib\n",
    "import os\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "query = [\"Serena Williams\"]\n",
    "\n",
    "for q in query:\n",
    "    search_and_download(q,\"C:\\\\code\\\\PROJECTS\\\\SportsPersonClassifier\\\\model\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b03cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70cf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc176011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
